{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Python\n",
    "# Lambdas\n",
    "\n",
    "Or sometimes called anonymous functions.\n",
    "\n",
    "In Python an anonymous function is created with the `lambda` keyword.\n",
    "\n",
    "Eventualy, it may or not be assigned a name.\n",
    "\n",
    "## Syntax\n",
    "\n",
    "Limitations:\n",
    "* Lambda can only contain expressions and can’t include statements in its body\n",
    "* Lambda is written as a single line of execution.\n",
    "* Lambda does not support type annotations.\n",
    "* It can be immediately invoked.\n",
    "\n",
    "Possible arguments:\n",
    "* Positional arguments\n",
    "* Named arguments (keyword arguments)\n",
    "* Variable list of arguments\n",
    "* Variable list of keyword arguments\n",
    "* Keyword-only arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x, y)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda x, y: x + y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdas can be used as an Immediately Invoked Function Expression.\n",
    "\n",
    "> Note: Python is not Javascript so doing this is not encouraged :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x, y: x + y)(2, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lambda function can be a higher-order function by taking a function (normal or lambda) as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "calculator = lambda x, y, operation: print(operation(x, y))\n",
    "\n",
    "calculator(2, 2, lambda a, b: a + b)\n",
    "calculator(2, 2, lambda a, b: a - b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood Python considers normal and lambda functions almost identical with only a naming difference.\n",
    "\n",
    "We'll see later in bytecode.\n",
    "\n",
    "Python style recommendations ([PEP-8](https://peps.python.org/pep-0008/#programming-recommendations)):\n",
    "> Always use a `def` statement instead of an assignment statement that binds a lambda expression directly to an identifier. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple return values and sequence unpacking\n",
    "\n",
    "In Python you can return multiple coma separated values from a function. \n",
    "\n",
    "It will return those values as a `tuple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiple_returns():\n",
    "    a = 2\n",
    "    b = 3\n",
    "    c = 4\n",
    "    return a, b, c\n",
    "\n",
    "result = multiple_returns()\n",
    "type(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can unpack those values into separate variables if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x, y, z = multiple_returns()\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `*` to add \"leftover\" variables to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "x, *y = multiple_returns()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `_` to \"skip\" some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "_, _, z = multiple_returns()\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `with` statement\n",
    "\n",
    "`with` functions similarly as `try-with-resources` in Java and ensures proper acquisition and release of resources.\n",
    "\n",
    "Instead of explicitly closing resources, e.g., when reading files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['print(\"hello, world!\")']\n"
     ]
    }
   ],
   "source": [
    "file = open('./hello.py', 'r')\n",
    "try:\n",
    "    print(file.readlines())\n",
    "finally:\n",
    "    file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `with` for a cleaner code. It allows you to enter the file context and execute code within it, while making sure the file resources will be freed upon exiting the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['print(\"hello, world!\")']\n"
     ]
    }
   ],
   "source": [
    "with open('./hello.py', 'r') as file:\n",
    "    print(file.readlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most things in Python data model, any object can work inside `with` statement using 2 dunder methods `__enter__()` and `__exit__()`:\n",
    "* `__enter__()` initializes the resource you wish to use in the object. It should always return a descriptor of the acquired resource.\n",
    "* `__exit__()` allows you to implement the release of acquired resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "    \n",
    "    def __enter__(self):\n",
    "        print(\"Entering filereader context\")\n",
    "        self.file = open(self.file_name, 'r')\n",
    "        return self.file\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        print(\"Exiting filereader context\")\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering filereader context\n",
      "['print(\"hello, world!\")']\n",
      "Exiting filereader context\n",
      "Outside of file reader context\n"
     ]
    }
   ],
   "source": [
    "with FileReader('./hello.py') as file:\n",
    "    print(file.readlines())\n",
    "print(\"Outside of file reader context\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__enter__()` and `__exit__()` interface is called `Context Manager`.\n",
    "\n",
    "You can simplify creating custom context objects using [contextlib](https://docs.python.org/3/library/contextlib.html) standard library module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "class FileReaderContext():\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "    \n",
    "    @contextmanager\n",
    "    def read_file(self):\n",
    "        try:\n",
    "            print(\"Entering filereader context\")\n",
    "            file = open(self.file_name, 'r')\n",
    "            yield file\n",
    "        finally:\n",
    "            print(\"Exiting filereader context\")\n",
    "            file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering filereader context\n",
      "['print(\"hello, world!\")']\n",
      "Exiting filereader context\n",
      "Outside of file reader context\n"
     ]
    }
   ],
   "source": [
    "reader = FileReaderContext('./hello.py')\n",
    "\n",
    "with reader.read_file() as file:\n",
    "    print(file.readlines())\n",
    "print(\"Outside of file reader context\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_file` is a generator function. When `read_file` is executed, it creates a resource descriptor and passes it to the caller using `yield`.\n",
    "\n",
    "After the code inside the `with` block is executed the program control returns back to the `read_file` function.\n",
    "\n",
    "The `read_file` function resumes its execution and executes the code following the `yield` statement, which releases the acquired resources.\n",
    "\n",
    "# Useful tools for data testing tasks\n",
    "\n",
    "## `datetime` module\n",
    "\n",
    "`datetime` module has 6 *main* classes \n",
    "\n",
    "* `date`: Gregorian calendar date. Its attributes are `year`, `month` and `day`.\n",
    "* `time`: time, independent of any particular day, assuming that every day has exactly `24*60*60` seconds. Its attributes are `hour`, `minute`, `second`, `microsecond`, and `tzinfo`.\n",
    "* `datetime`: combination of date and time along with the attributes year, month, day, hour, minute, second, microsecond, and tzinfo.\n",
    "* `timedelta`: duration expressing the difference between two date, time, or datetime instances to microsecond resolution.\n",
    "* `tzinfo`: provides time zone information objects.\n",
    "* `timezone`: class that implements the tzinfo abstract base class as a fixed offset from the UTC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date is 2023-01-25\n",
      "Current date is 2024-11-07\n",
      "Stringified date: 2023-01-25\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "simple_date = date(2023, 1, 25)\n",
    "\n",
    "print(f\"Date is {simple_date}\")\n",
    "print(f\"Current date is {date.today()}\")\n",
    "print(f\"Stringified date: {simple_date.isoformat()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time  is 13:24:56\n",
      "Stringified time: 13:24:56\n"
     ]
    }
   ],
   "source": [
    "from datetime import time\n",
    "\n",
    "simple_time = time(13, 24, 56)\n",
    "\n",
    "print(f\"Time  is {simple_time}\")\n",
    "print(f\"Stringified time: {simple_time.isoformat()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-26 00:00:00\n",
      "2023-01-26 23:01:26.123456\n",
      "1674766886.123456\n",
      "Today is: 2024-11-07 18:56:52.570816\n",
      "2024-11-07T18:56:52.570841\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "a = datetime(2023, 1, 26)\n",
    "print(a)\n",
    "\n",
    "a = datetime(2023, 1, 26, 23, 1, 26, 123456)\n",
    "print(a)\n",
    "\n",
    "print(a.timestamp())\n",
    "\n",
    "print(f\"Today is: {datetime.now()}\")\n",
    "\n",
    "print(datetime.now().isoformat())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-07 18:58:43.670716\n",
      "2026-11-07 18:58:43.670716\n",
      "2024-11-05 18:58:43.670716\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "time_now = datetime.now()\n",
    "\n",
    "date_after_2yrs = time_now + timedelta(days=730)\n",
    "\n",
    "date_before_2days = time_now - timedelta(days=2)\n",
    "\n",
    "print(time_now)\n",
    "print(date_after_2yrs)\n",
    "print(date_before_2days)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting date\n",
    "\n",
    "`strftime()` method converts the given date, time or datetime object to the a string representation of the given format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without formatting: 2024-11-07 18:59:57.094445\n",
      "Example 1: Thursday 11 2024\n",
      "Example 2: Thu 11 24\n",
      "Example 3: 6 PM 57\n",
      "Example 4: 18:59:57\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "now = dt.now()\n",
    "print(f\"Without formatting: {now}\")\n",
    "\n",
    "s = now.strftime(\"%A %m %-Y\")\n",
    "print(f\"Example 1: {s}\")\n",
    "\n",
    "s = now.strftime(\"%a %-m %y\")\n",
    "print(f\"Example 2: {s}\")\n",
    "\n",
    "s = now.strftime(\"%-I %p %S\")\n",
    "print(f\"Example 3: {s}\")\n",
    "\n",
    "s = now.strftime(\"%H:%M:%S\")\n",
    "print(f\"Example 4: {s}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-07 17:03:16 UTC+0000\n",
      "2024-11-07 19:03:16 EET+0200\n",
      "2024-11-07 12:03:16 EST-0500\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "format = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "\n",
    "now_utc = datetime.now(timezone('UTC'))\n",
    "print(now_utc.strftime(format))\n",
    "\n",
    "timezones = ['Europe/Kiev', 'America/New_York']\n",
    "\n",
    "for tzone in timezones:\n",
    "    now_world = now_utc.astimezone(timezone(tzone))\n",
    "    print(now_world.strftime(format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON processing\n",
    "\n",
    "Python comes with a built-in package called [json](https://docs.python.org/3/library/json.html) for working with JSON data.\n",
    "\n",
    "### Serialization\n",
    "Python objects to JSON convertion:\n",
    "\n",
    "| Python         | JSON       |\n",
    "|----------------|------------|\n",
    "| dict           | object     |\n",
    "| list, tuple    | array      |\n",
    "| str            | string     |\n",
    "| int,float,long | number     |\n",
    "| True,False     | true,false |\n",
    "| None           | null       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "\t\"id\": \"0001\",\n",
    "\t\"type\": \"donut\",\n",
    "\t\"name\": \"Cake\",\n",
    "\t\"ppu\": 0.55,\n",
    "\t\"batters\":\n",
    "\t\t{\n",
    "\t\t\t\"batter\":\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\t{ \"id\": \"1001\", \"type\": \"Regular\" },\n",
    "\t\t\t\t\t{ \"id\": \"1002\", \"type\": \"Chocolate\" },\n",
    "\t\t\t\t\t{ \"id\": \"1003\", \"type\": \"Blueberry\" },\n",
    "\t\t\t\t\t{ \"id\": \"1004\", \"type\": \"Devil's Food\" }\n",
    "\t\t\t\t]\n",
    "\t\t},\n",
    "\t\"topping\":\n",
    "\t\t[\n",
    "\t\t\t{ \"id\": \"5001\", \"type\": \"None\" },\n",
    "\t\t\t{ \"id\": \"5002\", \"type\": \"Glazed\" },\n",
    "\t\t\t{ \"id\": \"5005\", \"type\": \"Sugar\" },\n",
    "\t\t\t{ \"id\": \"5007\", \"type\": \"Powdered Sugar\" },\n",
    "\t\t\t{ \"id\": \"5006\", \"type\": \"Chocolate with Sprinkles\" },\n",
    "\t\t\t{ \"id\": \"5003\", \"type\": \"Chocolate\" },\n",
    "\t\t\t{ \"id\": \"5004\", \"type\": \"Maple\" }\n",
    "\t\t]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"0001\", \"type\": \"donut\", \"name\": \"Cake\", \"ppu\": 0.55, \"batters\": {\"batter\": [{\"id\": \"1001\", \"type\": \"Regular\"}, {\"id\": \"1002\", \"type\": \"Chocolate\"}, {\"id\": \"1003\", \"type\": \"Blueberry\"}, {\"id\": \"1004\", \"type\": \"Devil\\'s Food\"}]}, \"topping\": [{\"id\": \"5001\", \"type\": \"None\"}, {\"id\": \"5002\", \"type\": \"Glazed\"}, {\"id\": \"5005\", \"type\": \"Sugar\"}, {\"id\": \"5007\", \"type\": \"Powdered Sugar\"}, {\"id\": \"5006\", \"type\": \"Chocolate with Sprinkles\"}, {\"id\": \"5003\", \"type\": \"Chocolate\"}, {\"id\": \"5004\", \"type\": \"Maple\"}]}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.dumps(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serialize to any file-type destinations\n",
    "\n",
    "Can use `indent` keyword to pretty format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserialization\n",
    "JSON to Python objects convertion:\n",
    "\n",
    "| JSON         | Python     |\n",
    "|--------------|------------|\n",
    "| object       | dict       |\n",
    "| array        | list       |\n",
    "| string       | str        |\n",
    "| number(int)  | int        |\n",
    "| number(real) | float      |\n",
    "| true,false   | True,False |\n",
    "| null         | None       |\n",
    "\n",
    "> Note: little difference between serialization & deserialization types. Meaning you may not get the \"exact\" object if you serialize it in one part of your application and desererialize in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<class 'tuple'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "important_data = (1,2,3)\n",
    "encoded = json.dumps(important_data)\n",
    "decoded = json.loads(encoded)\n",
    "\n",
    "print(important_data == decoded)\n",
    "print(type(important_data))\n",
    "print(type(decoded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom types\n",
    "\n",
    "#### Serialization\n",
    "\n",
    "* encoder function\n",
    "* encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of type datetime is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "user = {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"Mykola\",\n",
    "    \"createdAt\": datetime.datetime.now()\n",
    "}\n",
    "\n",
    "try:\n",
    "    json.dumps(user)\n",
    "except TypeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 1, \"name\": \"Mykola\", \"createdAt\": \"2024-11-07T19:10:36.795644\"}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_datetime(dt):\n",
    "    if isinstance(dt, (datetime.date, datetime.datetime)):\n",
    "        return dt.isoformat()\n",
    "    else:\n",
    "        type_name = dt.__class__.__name__\n",
    "        raise TypeError(f\"Object of type '{type_name}' is not JSON serializable\")\n",
    "\n",
    "json.dumps(user, default=encode_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 1, \"name\": \"Mykola\", \"createdAt\": \"2024-11-07T19:10:36.795644\"}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, dt):\n",
    "        if isinstance(dt, (datetime.date, datetime.datetime)):\n",
    "            return dt.isoformat()\n",
    "        else:\n",
    "            return super().default(dt)\n",
    "\n",
    "json.dumps(user, cls=DateTimeEncoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deserialization\n",
    "\n",
    "As in other languages - need to figure out if there is a custom type by some marker, for example field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Mykola',\n",
       " 'createdAt': datetime.datetime(2024, 11, 7, 19, 10, 36, 795644)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "json_data = \"\"\"{\"id\": 1, \"name\": \"Mykola\", \"createdAt\": \"2024-11-07T19:10:36.795644\"}\"\"\"\n",
    "\n",
    "def decode_datetime(dct):\n",
    "    if \"createdAt\" in dct:\n",
    "        dct[\"createdAt\"] = datetime.datetime.fromisoformat(dct[\"createdAt\"])\n",
    "    return dct\n",
    "\n",
    "json.loads(json_data, object_hook=decode_datetime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Schema validation\n",
    "\n",
    "A [JSON Schema](https://json-schema.org/) is a JSON document defining the schema of some JSON data.\n",
    "\n",
    "It is a valid JSON document with key/value pairs. Each key has a special meaning and is used to define the schema of some JSON data\n",
    "\n",
    "It's a good way to validate your data, especially if you receive similar objects from different sources.\n",
    "\n",
    "There are two schema keywords, namely `$schema` and `$id`. `$schema` defines the “[draft](https://json-schema.org/specification-links.html)” that is used for the schema. If `$schema` is not specified, the latest draft will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"id\": {\"type\": \"number\"},\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"createdAt\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"id\", \"name\", \"createdAt\"],\n",
    "    \"additionalProperties\": False\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has the [jsonschema](https://pypi.org/project/jsonschema/) library to validate a JSON *instance* against a schema. It is very easy to validate schema using its `validate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import validate, ValidationError\n",
    "import json\n",
    "\n",
    "json_from_datasource = \"\"\"{\"id\": 1, \"name\": \"Mykola\", \"createdAt\": \"2023-01-25T12:29:25.996855\"}\"\"\"\n",
    "json_data = json.loads(json_from_datasource)\n",
    "\n",
    "validate(instance=json_data, schema=user_schema)\n",
    "# No error, the JSON is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'1' is not of type 'number'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['id']:\n",
      "    {'type': 'number'}\n",
      "\n",
      "On instance['id']:\n",
      "    '1'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validate(instance={\"id\": \"1\", \"name\": \"Mykola\", \"createdAt\": \"2023-01-25T12:29:25.996855\"}, schema=user_schema)\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'id' is a required property\n",
      "\n",
      "Failed validating 'required' in schema:\n",
      "    {'type': 'object',\n",
      "     'properties': {'id': {'type': 'number'},\n",
      "                    'name': {'type': 'string'},\n",
      "                    'createdAt': {'type': 'string'}},\n",
      "     'required': ['id', 'name', 'createdAt'],\n",
      "     'additionalProperties': False}\n",
      "\n",
      "On instance:\n",
      "    {'name': 'Mykola'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validate(instance={\"name\": \"Mykola\"}, schema=user_schema)\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional properties are not allowed ('job' was unexpected)\n",
      "\n",
      "Failed validating 'additionalProperties' in schema:\n",
      "    {'type': 'object',\n",
      "     'properties': {'id': {'type': 'number'},\n",
      "                    'name': {'type': 'string'},\n",
      "                    'createdAt': {'type': 'string'}},\n",
      "     'required': ['id', 'name', 'createdAt'],\n",
      "     'additionalProperties': False}\n",
      "\n",
      "On instance:\n",
      "    {'id': 1,\n",
      "     'name': 'Mykola',\n",
      "     'createdAt': '2023-01-25T12:29:25.996855',\n",
      "     'job': 'Engineer'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    validate(instance={\"id\": 1, \"name\": \"Mykola\", \"createdAt\": \"2023-01-25T12:29:25.996855\", \"job\": \"Engineer\"}, schema=user_schema)\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a valid JSON schema and want to use it to validate many JSON documents, then it’s recommended to use a `Validator`.\n",
    "\n",
    "You can also use it to validate the schema definition itself against a given draft spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import Draft202012Validator\n",
    "\n",
    "Draft202012Validator.check_schema(user_schema)\n",
    "# No output means the schema is valid, otherwise `SchemaError` will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_202012_validator = Draft202012Validator(user_schema)\n",
    "\n",
    "draft_202012_validator.validate(json_data)\n",
    "# No output, the JSON is valid.\n",
    "# Otherwise, ValidationError will be raised as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don't want to deal with errors\n",
    "draft_202012_validator.is_valid(json_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with HTTP\n",
    "\n",
    "Two main libraries:\n",
    "* [urllib.request](https://docs.python.org/3/library/urllib.request.html): part of standard library. Low level API for accessing (mostly http) urls.\n",
    "* [requests](https://requests.readthedocs.io/en/latest/): high level API. One love :)\n",
    "\n",
    "`requests` has a lot of features. Just a showcase how easy it is to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "print(response.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP error codes as exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "HTTP error occurred: 404 Client Error: Not Found for url: https://jsonplaceholder.typicode.com/invalid\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "for url in ['https://jsonplaceholder.typicode.com/todos', 'https://jsonplaceholder.typicode.com/invalid']:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "    else:\n",
    "        print('Success!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"userId\": 1,\\n  \"id\": 1,\\n  \"title\": \"delectus aut autem\",\\n  \"completed\": false\\n}'\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://jsonplaceholder.typicode.com/todos/1\")\n",
    "# raw response bytes\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': 1, 'id': 1, 'title': 'delectus aut autem', 'completed': False}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response as string\n",
    "string = response.text\n",
    "json.loads(string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't need custom processing - use build in method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': 1, 'id': 1, 'title': 'delectus aut autem', 'completed': False}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id labore ex et quam laborum'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\n",
    "    'https://jsonplaceholder.typicode.com/comments',\n",
    "    params={'postId': 1},\n",
    ")\n",
    "decoded = response.json()\n",
    "decoded[0][\"name\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests` supports all http method, e.g. `POST` & `PUT`\n",
    "\n",
    "* `data` - encodes dictionary as `application/x-www-form-urlencoded`\n",
    "* `json` - JSON encoding\n",
    "\n",
    "```python\n",
    "requests.post('https://httpbin.org/post', data={'key':'value'})\n",
    "requests.put('https://httpbin.org/put', json={'key':'value'})\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging in Python\n",
    "\n",
    "It is easy to debug in IDE.\n",
    "\n",
    "But there may be situations where you have Python a script, a terminal a possible bug and no IDE :)\n",
    "\n",
    "Python has a built-in debugger [pdb](https://docs.python.org/3/library/pdb.html) that you can use both in the REPL and as a standalone module.\n",
    "\n",
    "It's not as powerfull as some IDE debuggers and requires you to use `__repr__()` in your classes :) but still if nothign else available - it is a great way to see whats going on.\n",
    "\n",
    "## *invasive* and *noninvasive* debugging\n",
    "\n",
    "If you know where the problem is and can (or want to) modify your code, you can use a built-in `breakpoint()` function to enable debugging where you want to. This works is Python 3.7+.\n",
    "\n",
    "You can also control if the interpreter should execute the `breakpoint()` function by setting the `PYTHONBREAKPOINT` environment variable.\n",
    "\n",
    "`PYTHONBREAKPOINT=0` will disable `breakpoint()` function.\n",
    "\n",
    "> Note: As debugging is interactive you need to run examples in terminal with activated venv instead of notebook.\n",
    "\n",
    "Simple usage of `breakpoint` in file will stop execution and enable debugging:\n",
    "\n",
    "```bash\n",
    "python debugging/invasive_debugging.py\n",
    "```\n",
    "\n",
    "You can also run a script or even some functions from a module using `pdb` without code modifications.\n",
    "\n",
    "If you want to run `pdb` in REPL you can start it by running `python`, then inside the REPL:\n",
    "\n",
    "```python\n",
    "import pdb\n",
    "import your_module\n",
    "\n",
    "pdb.run(\"your_module.some_function()\")\n",
    "```\n",
    "\n",
    "Or just run `python -m pdb your_module.py` in terminal.\n",
    "\n",
    "This will enable `pdb` from the beginning of your script. For example:\n",
    "\n",
    "```bash\n",
    "python -m pdb debugging/noninvasive_debugging.py\n",
    "```\n",
    "\n",
    "## Commands\n",
    "\n",
    "You can navigate your debugging environment using `pdb` commands. Some are listed here, rest aer listed in documentation.\n",
    "\n",
    "| Command | Action                                                                                                                                                                                                   |\n",
    "|---------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `p`       | Print the value of an expression.                                                                                                                                                                        |\n",
    "| `pp`      | Pretty-print the value of an expression.                                                                                                                                                                 |\n",
    "| `n`       | Continue execution until the next line in the current function is reached or it returns.                                                                                                                 |\n",
    "| `s`       | Execute the current line and stop at the first possible occasion (either in a function that is called or in the current function).                                                                       |\n",
    "| `c`       | Continue execution and only stop when a breakpoint is encountered.                                                                                                                                       |\n",
    "| `unt`     | Continue execution until the line with a number greater than the current one is reached. With a line number argument, continue execution until a line with a number greater or equal to that is reached. |\n",
    "| `l`       | List source code for the current file. Without arguments, list `11` lines around the current line or continue the previous listing.                                                                        |\n",
    "| `ll`      | List the whole source code for the current function or frame.                                                                                                                                            |\n",
    "| `b`       | With no arguments, list all breaks. With a line number argument, set a breakpoint at this line in the current file.                                                                                      |\n",
    "| `w`       | Print a stack trace, with the most recent frame at the bottom. An arrow indicates the current frame, which determines the context of most commands.                                                      |\n",
    "| `u`       | Move the current frame count (default one) levels up in the stack trace (to an older frame).                                                                                                             |\n",
    "| `d`       | Move the current frame count (default one) levels down in the stack trace (to a newer frame).                                                                                                            |\n",
    "| `h`       | List of available commands                                                                                                                                                                               |\n",
    "| `q`       | Quit the debugger                                                                                                                                                                                        |\n",
    "\n",
    "### Printing\n",
    "\n",
    "Allows evaluation of any valid Python expression.\n",
    "\n",
    "```bash\n",
    "python debugging/printing.py\n",
    "```\n",
    "\n",
    "Inside the debugger you can run any of the following commands:\n",
    "\n",
    "```python\n",
    "p filename\n",
    "p head,tail\n",
    "p 'filename: ' + filename\n",
    "p get_path\n",
    "p getattr(get_path, '__doc__')\n",
    "pp [os.path.split(p)[1] for p in os.path.sys.path]\n",
    "```\n",
    "\n",
    "> Note: last command is pretty print :)\n",
    "\n",
    "### Navigation\n",
    "\n",
    "* `n` allows to continue to next line or until function returns. \"Step over\" in debugging UI.\n",
    "* `s` allows to execute the current line and stop at the first possible occasion. \"Step into\" int debugging UI.\n",
    "* `c` allows to continue execution until next breakpoint.\n",
    "* `unt` allows to continue until the given line number.\n",
    "\n",
    "You can use this script to experiment:\n",
    "\n",
    "```bash\n",
    "python debugging/stepping.py\n",
    "```\n",
    "\n",
    "### Dynamic breakpoints\n",
    "\n",
    "You can tell `pdb` to create breakpoints on a line number or a function name and even specify conditions when these breakpoints should be created.\n",
    "\n",
    "```\n",
    "b(reak) [ ([filename:]lineno | function) [, condition] ]\n",
    "```\n",
    "\n",
    "You can experiment with\n",
    "\n",
    "```bash\n",
    "python debugging/breakpoint.py\n",
    "```\n",
    "\n",
    "Inside debugger set `b util:4` (and check the variables `p filename, head, tail` inside the function body) or `b util.get_path` (and check the function args `p filename` or using a simple `a` command to list function arguments). Use `c` to navigate to the breakpoint.\n",
    "\n",
    "`b` without arguments lists all available breakpoints. You can disable and enable them by their number, e.g., `disable 1` or `enable 1`, or even remove them using clear, e.g., `clear 1`.\n",
    "\n",
    "## Tracking value changes\n",
    "\n",
    "You can use `display` and `undisplay` to track and untrack certain expressions. If their result changes - debugger will break.\n",
    "\n",
    "You can experiment with\n",
    "\n",
    "```bash\n",
    "python debugging/display.py\n",
    "```\n",
    "\n",
    "by setting a breakpoint on line 6 (`b 6`) and when you reach it ask debugger to `display char`. When you continue (`c`) you'll see the result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cool things you might never use :)\n",
    "\n",
    "Because frameworks got you covered. But just in case you'll need it somewhere.\n",
    "\n",
    "## Coroutines\n",
    "\n",
    "Coroutines are generalizations of subroutines (a.k.a. functions). They are used for cooperative multitasking where a process voluntarily `yield` control periodically or when idle in order to enable multiple applications to be run simultaneously. The difference between coroutine and function is:\n",
    "* Unlike functions, coroutines have many entry points for suspending and resuming execution. Coroutine can suspend its execution and transfer control to other coroutine and can resume again execution from the point it left off. \n",
    "* Unlike functions, there is no main function to call coroutines in a particular order and coordinate the results. Coroutines are cooperative that means they link together to form a pipeline. One coroutine may consume input data and send it to other that process it. Finally, there may be a coroutine to display the result.\n",
    "\n",
    "Coroutines are commonly used when dealing with concepts such as an **event loop** (which Python’s `asyncio` is built upon)\n",
    "\n",
    "### Coroutines vs Threads\n",
    "\n",
    "* Thread\n",
    "    * an operating system (or run time environment) switches between threads according to the scheduler.\n",
    "* Coroutine\n",
    "    * programmer and programming language decide when to switch coroutines. Coroutines work cooperatively multitask by suspending and resuming at set points by the programmer.\n",
    "\n",
    "### Recap on generators\n",
    "\n",
    "Generators allow us to pull data and pause execution from a function context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(limit):\n",
    "    n2 = 1\n",
    "    if limit >= 1:\n",
    "        print(\"pausing execution and return n2\")\n",
    "        yield n2\n",
    "        print(\"resume execution after n2\")\n",
    "        n1 = 0\n",
    "        for _ in range(1, limit):\n",
    "            n = n1 + n2\n",
    "            print(\"pausing execution and return n\")\n",
    "            yield n\n",
    "            print(\"resume execution after n\")\n",
    "            n1, n2 = n2, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pausing execution and return n2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "fib = fibonacci(5)\n",
    "print(next(fib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume execution after n2\n",
      "pausing execution and return n\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(next(fib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume execution after n\n",
      "pausing execution and return n\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(next(fib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume execution after n\n",
      "pausing execution and return n\n",
      "3\n",
      "resume execution after n\n",
      "pausing execution and return n\n",
      "5\n",
      "resume execution after n\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(next(fib))\n",
    "print(next(fib))\n",
    "try:\n",
    "    print(next(fib))\n",
    "except StopIteration:\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asyncio - native (new) coroutines :)\n",
    "\n",
    "* simple coroutines - traditional generator coroutine (no async io).\n",
    "* native coroutines - `asyncio` using latest `async`/`await` implementation.\n",
    "\n",
    "Before Python 3.10 `asyncio` implementation used another implementation of generator coroutines. Now this is deprecated.\n",
    "\n",
    "New coroutines created with `async def` are implemented using the new `__await__()` magic method ([more in python data model](https://docs.python.org/3/reference/datamodel.html#coroutines)).\n",
    "\n",
    "`asyncio` is evolving pretty fast and has additional cool things like tasks, futures, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "\n",
    "async def concurent_task_1(n: int) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"concurent_task_1({n}) sleeping for {i} seconds.\")\n",
    "    await asyncio.sleep(i)\n",
    "    result = f\"result{n}-1\"\n",
    "    print(f\"Returning concurent_task_1({n}) == {result}.\")\n",
    "    return result\n",
    "\n",
    "async def concurent_task_2(n: int, arg: str) -> str:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"concurent_task_2{n, arg} sleeping for {i} seconds.\")\n",
    "    await asyncio.sleep(i)\n",
    "    result = f\"result{n}-2 derived from {arg}\"\n",
    "    print(f\"Returning concurent_task_2{n, arg} == {result}.\")\n",
    "    return result\n",
    "\n",
    "async def chain(n: int) -> None:\n",
    "    start = time.perf_counter()\n",
    "    p1 = await concurent_task_1(n)\n",
    "    p2 = await concurent_task_2(n, p1)\n",
    "    end = time.perf_counter() - start\n",
    "    print(f\"-->Chained result{n} => {p2} (took {end:0.2f} seconds).\")\n",
    "\n",
    "async def main(*args):\n",
    "    await asyncio.gather(*(chain(n) for n in args))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run it using normal Python script like this:\n",
    "\n",
    "```python\n",
    "random.seed(111)\n",
    "\n",
    "args = [1, 2, 3]\n",
    "\n",
    "start = time.perf_counter()\n",
    "# this is important for \"normal\" scripts\n",
    "asyncio.run(main(*args))\n",
    "end = time.perf_counter() - start\n",
    "print(f\"Program finished in {end:0.2f} seconds.\")\n",
    "```\n",
    "\n",
    "But as we already are running inside an existing event loop in Jupyter we can do it another way :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concurent_task_1(1) sleeping for 3 seconds.\n",
      "concurent_task_1(2) sleeping for 5 seconds.\n",
      "concurent_task_1(3) sleeping for 7 seconds.\n",
      "Returning concurent_task_1(1) == result1-1.\n",
      "concurent_task_2(1, 'result1-1') sleeping for 3 seconds.\n",
      "Returning concurent_task_1(2) == result2-1.\n",
      "concurent_task_2(2, 'result2-1') sleeping for 6 seconds.\n",
      "Returning concurent_task_2(1, 'result1-1') == result1-2 derived from result1-1.\n",
      "-->Chained result1 => result1-2 derived from result1-1 (took 6.00 seconds).\n",
      "Returning concurent_task_1(3) == result3-1.\n",
      "concurent_task_2(3, 'result3-1') sleeping for 6 seconds.\n",
      "Returning concurent_task_2(2, 'result2-1') == result2-2 derived from result2-1.\n",
      "-->Chained result2 => result2-2 derived from result2-1 (took 11.00 seconds).\n",
      "Returning concurent_task_2(3, 'result3-1') == result3-2 derived from result3-1.\n",
      "-->Chained result3 => result3-2 derived from result3-1 (took 13.00 seconds).\n",
      "Program finished in 13.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "random.seed(111)\n",
    "\n",
    "args = [1, 2, 3]\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Works in Jupyter as we already run inside asyncio\n",
    "await main(*args)\n",
    "end = time.perf_counter() - start\n",
    "print(f\"Program finished in {end:0.2f} seconds.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads\n",
    "### Note on GIL\n",
    "\n",
    "Why so much hassle for concurrency? Why not good old threads?\n",
    "\n",
    "In Python, although multithreading is supported by utilizing actual OS threads (POSIX threads on Unix and Windows threads), because of the Global Interpreter Lock (GIL), multithreading always happens on **one CPU**, thus parallelism is not possible. Only concurrency is possible in Python.\n",
    "\n",
    "The GIL prevents context switches from happening in the middle of C code. Basically, it makes any C code into a critical section, except when that C code explicitly releases the GIL. This greatly simplifies the task of writing extension modules as well the Python core.\n",
    "\n",
    "The designers of Python made a design decision that extension writers would not have to take care of locking. Thus, Python is intended to be simple/easy to integrate with any C library. In order to remove the GIL, you’d have to go into all existing C code and write explicit locking/unlocking code, and you’d have to do this with every new C library as well.\n",
    "\n",
    "Other then that, Threads are pretty similar to Java.\n",
    "\n",
    "> Note: well and you kinda can't use them for CPU intensive work :)\n",
    "\n",
    "> Note 2: It's usualy too much headache to use threads so `asyncio` wins :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "def run_thread(n_max: int = 1_000_000) -> None:\n",
    "    n = 0\n",
    "    while n < n_max:\n",
    "        n += 1\n",
    "\n",
    "\n",
    "my_thread = Thread(target=run_thread, args=(10_000_000,))\n",
    "my_thread.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extending Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThread(Thread):\n",
    "    def __init__(self, n_max=1_000_000) -> None:\n",
    "        Thread.__init__(self)\n",
    "        self.n_max = n_max\n",
    "\n",
    "    def run(self) -> None:\n",
    "        n = 0\n",
    "        while n < self.n_max:\n",
    "            n += 1\n",
    "\n",
    "\n",
    "my_thread = MyThread(n_max=1_000_000)\n",
    "my_thread.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data from Thread using Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "def run_thread(result_queue: Queue) -> None:\n",
    "    print(\"thread doing work...\")\n",
    "    time.sleep(2)\n",
    "    func_result = \"result\"\n",
    "    # put result in queue\n",
    "    result_queue.put(func_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread doing work...\n",
      "result from queue\n"
     ]
    }
   ],
   "source": [
    "func_result_queue: Queue = Queue(maxsize=0)\n",
    "\n",
    "thread = Thread(target=run_thread, args=(func_result_queue,))\n",
    "thread.start()\n",
    "\n",
    "func_result = func_result_queue.get()\n",
    "print(func_result, \"from queue\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThreadPoolExecutor :)\n",
    "<img src=\"images/dicaprio.jpeg\" style=\"background:none; border:none; box-shadow:none; display:inline; margin:0; vertical-align:middle;\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the task 1...Starting the task 2...\n",
      "\n",
      "Done with task 1\n",
      "Done with task 2\n",
      "It took 2.005678737012204 second(s) to finish.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "def task(id):\n",
    "    print(f'Starting the task {id}...')\n",
    "    time.sleep(2)\n",
    "    return f'Done with task {id}'\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    f1 = executor.submit(task, 1)\n",
    "    f2 = executor.submit(task, 2)\n",
    "\n",
    "    print(f1.result())\n",
    "    print(f2.result())\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f\"It took {finish-start} second(s) to finish.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "As in true parallelism you will need to \"write parallel code\" and separate a larger task into many smaller jobs that can be executed in parallel. Also you need to implement coordination, communication, and synchronization between processes which is not alwasy easy.\n",
    "\n",
    "> Note: It's a complex topic so we'll just glance over a few examples.\n",
    "\n",
    "### Spin up a process\n",
    "\n",
    "If you are running Linux it might be easy to run processes in Jupyter :)\n",
    "\n",
    "On other OS spawning is available only in `__main__` modules.\n",
    "\n",
    "```python\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "def do_stuff(sleep_secs: int) -> None:\n",
    "    print(\"doing stuff...\")\n",
    "    time.sleep(sleep_secs)\n",
    "    print(\"stuff done\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    proc = Process(target=do_stuff, args=(10,))\n",
    "    proc.start()\n",
    "    proc.join()\n",
    "```\n",
    "\n",
    "We can create multiple sub-processes (though they are \"heavier\" than threads and especially coroutines).\n",
    "\n",
    "You can use [*multiprocessing contexts*](https://docs.python.org/3/library/multiprocessing.html) you to select how a child process starts (what it inherits from the parent process). There are three choices:\n",
    "\n",
    "* `spawn`: Starts an entirely new Python process. The new process will not inherit unnecessary objects from the parent. In particular, it does not copy thread locks. This method is the default for macOS and Windows.\n",
    "* `fork`: It is a copy of the parent process. While it does not copy threads, it does copy thread locks. It is the default in Unix. This method is considered thread-unsafe and, in particular, may cause crashes in subprocesses on macOS.\n",
    "* `forkserver`: When first started, it creates a fresh Python process and a server. Whenever we want to start a new process, we connect to the server and request a fork of the initially created fresh Python process.\n",
    "\n",
    "```python\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "def do_stuff(sleep_secs: int) -> None:\n",
    "    print(\"doing stuff...\")\n",
    "    time.sleep(sleep_secs)\n",
    "    print(\"stuff done\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method(\"fork\")\n",
    "    proc = mp.Process(target=do_stuff, args=(10,))\n",
    "    proc.start()\n",
    "    proc.join()\n",
    "```\n",
    "\n",
    "But generally, creating and managing processes is a pain (and if you read the docs you'll see why :)).\n",
    "\n",
    "Most of the time, they are used to remove some CPU-intensive task from the main process (possibly parallel computing).\n",
    "\n",
    "The `Pool` takes care of process creation and communication for us. Besides, the pool interface is designed for submitting tasks. Much like `ThreadPoolExecutor` but for processes.\n",
    "\n",
    "```python\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time\n",
    "\n",
    "def task(id):\n",
    "    print(f'Starting the task {id}...')\n",
    "    time.sleep(2)\n",
    "    return f'Done with task {id}'\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "with Pool(processes=2) as executor:\n",
    "    f1 = executor.apply(task, 1)\n",
    "    f2 = executor.apply(task, 2)\n",
    "\n",
    "    print(f1.result())\n",
    "    print(f2.result())\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f\"It took {finish-start} second(s) to finish.\")\n",
    "```\n",
    "\n",
    "There's also a `ProcessPoolExecutor` class in the `concurrent.futures` package to combine multithreading and multiprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e50a75acf12e54d10fc4ec181faf7e3047482c971076bcb746266dcf5f0b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
